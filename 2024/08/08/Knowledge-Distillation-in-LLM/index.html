<!DOCTYPE html>
<html lang="zh-Hans">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">
  <link rel="apple-touch-icon" sizes="180x180" href="/hexo_blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/hexo_blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/hexo_blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/hexo_blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/hexo_blog/css/main.css">


<link rel="stylesheet" href="/hexo_blog/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"wnma3mz.github.io","root":"/hexo_blog/","scheme":"Mist","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="ä»çŸ¥è¯†è’¸é¦çš„æ¦‚å¿µå‡ºå‘ï¼Œä»‹ç» LLM ä¸­çš„çŸ¥è¯†è’¸é¦">
<meta property="og:type" content="article">
<meta property="og:title" content="Knowledge Distillation in LLM">
<meta property="og:url" content="https://wnma3mz.github.io/2024/08/08/Knowledge-Distillation-in-LLM/index.html">
<meta property="og:site_name" content="Wnma&#39;s Blogs">
<meta property="og:description" content="ä»çŸ¥è¯†è’¸é¦çš„æ¦‚å¿µå‡ºå‘ï¼Œä»‹ç» LLM ä¸­çš„çŸ¥è¯†è’¸é¦">
<meta property="og:locale">
<meta property="article:published_time" content="2024-08-08T02:44:12.000Z">
<meta property="article:modified_time" content="2024-09-08T04:57:29.907Z">
<meta property="article:author" content="wnma3mz">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="knowledge distillation">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://wnma3mz.github.io/2024/08/08/Knowledge-Distillation-in-LLM/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-Hans'
  };
</script>

  <title>Knowledge Distillation in LLM | Wnma's Blogs</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="ØªØ´ØºÙŠÙ„ Ø´Ø±ÙŠØ· Ø§Ù„ØªØµÙØ­">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/hexo_blog/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Wnma's Blogs</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/hexo_blog/" rel="section"><i class="fa fa-home fa-fw"></i>é¦–é¡µ</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/hexo_blog/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>æ ‡ç­¾</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/hexo_blog/categories/" rel="section"><i class="fa fa-th fa-fw"></i>åˆ†ç±»</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/hexo_blog/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>å½’æ¡£</a>

  </li>
        <li class="menu-item menu-item-bookmark">

    <a href="https://wnma3mz.github.io/bookmark/index.html" rel="section"><i class="fa fa-bookmark fa-fw"></i>ä¹¦ç­¾</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>æœç´¢
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="æœç´¢..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-Hans">
    <link itemprop="mainEntityOfPage" href="https://wnma3mz.github.io/2024/08/08/Knowledge-Distillation-in-LLM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://avatars.githubusercontent.com/u/23001152?s=460&u=dacc012cd237ac86458d888b3723d1d495cb1aa4&v=4">
      <meta itemprop="name" content="wnma3mz">
      <meta itemprop="description" content="Day Day Up">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Wnma's Blogs">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Knowledge Distillation in LLM
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">å‘è¡¨äº</span>

              <time title="åˆ›å»ºäºï¼š2024-08-08 10:44:12" itemprop="dateCreated datePublished" datetime="2024-08-08T10:44:12+08:00">2024-08-08</time>

            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">æ›´æ–°äº</span>
                <time title="Ø¹ÙØ¯Ù„ï¼š2024-09-08 12:57:29" itemprop="dateModified" datetime="2024-09-08T12:57:29+08:00">2024-09-08</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">åˆ†ç±»äº</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/hexo_blog/categories/PaperReading/" itemprop="url" rel="index"><span itemprop="name">PaperReading</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>ä»çŸ¥è¯†è’¸é¦çš„æ¦‚å¿µå‡ºå‘ï¼Œä»‹ç» LLM ä¸­çš„çŸ¥è¯†è’¸é¦</p>
<span id="more"></span>
<h2 id="outlines">Outlines</h2>
<ul>
<li>Knowledge Distillationï¼ˆçŸ¥è¯†è’¸é¦ï¼‰
<ul>
<li>æ˜¯ä»€ä¹ˆ</li>
<li>æ€ä¹ˆåš</li>
</ul></li>
<li>LLM ä¸­çš„ KD åŠå…¶å˜ç§
<ul>
<li>Reverse KD</li>
<li>JS æ•£åº¦</li>
</ul></li>
<li>è®ºæ–‡
<ul>
<li>MiniLLM: Knowledge Distillation of Large Language Models</li>
<li>Revisiting Knowledge Distillation for Autoregressive Language
Models</li>
</ul></li>
</ul>
<h2 id="çŸ¥è¯†è’¸é¦æ˜¯ä»€ä¹ˆ">çŸ¥è¯†è’¸é¦æ˜¯ä»€ä¹ˆ</h2>
<p><strong>è’¸é¦çš„ä½œç”¨</strong>ï¼šæ¸…é™¤ç»å¤§éƒ¨åˆ†æ‚è´¨å’Œæ€æ­»å¾®ç”Ÿç‰©</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd1.png" /></p>
<p><strong>çŸ¥è¯†</strong>ï¼šé«˜åº¦æŠ½è±¡çš„æ¦‚å¿µ</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd2.png" /></p>
<p>åœ¨æ·±åº¦å­¦ä¹ æ¨¡å‹é‡Œé¢ï¼Œå°†å…¶å…·è±¡ä¸ºï¼š</p>
<ul>
<li><p>æ¨¡å‹æƒé‡ï¼šè‹¥å¹²å›ºå®šå¥½çš„çŸ©é˜µ</p></li>
<li><p>æ¨¡å‹è¾“å‡ºï¼šæ¨¡å‹å¯¹äºè¾“å…¥çš„å“åº”</p></li>
</ul>
<p>æ›´å…·ä½“çš„ï¼Œå¯¹äºä¸€ä¸ªä¸‰åˆ†ç±»æ¨¡å‹ï¼Œæ¨¡å‹æœ€åè¾“å‡ºçš„æ˜¯ logitsã€‚</p>
<p>å¦‚ï¼š<span class="math inline">\([0.2, 0.3,
0.5]\)</span>ï¼Œè¿™ä¸ªå¯ä»¥è¢«è®¤ä¸ºæ˜¯æ¨¡å‹çŸ¥è¯†çš„ä¸€ç§ã€‚</p>
<h2 id="æ€ä¹ˆåšçŸ¥è¯†è’¸é¦">æ€ä¹ˆåšçŸ¥è¯†è’¸é¦</h2>
<h3 id="ç»å…¸çš„è®­ç»ƒæ–¹æ³•">ç»å…¸çš„è®­ç»ƒæ–¹æ³•</h3>
<p>ä¸‰åˆ†ç±»ä»»åŠ¡ï¼Œå¯¹äºè¾“å…¥ <span class="math inline">\(X\)</span></p>
<p>çœŸå®æ ‡ç­¾æ˜¯ç¬¬ 0 ä¸ªç±»åˆ«ï¼Œä¼šå°†å…¶ one-hot ä¸º <span
class="math inline">\([1, 0, 0]\)</span></p>
<p>æ¨¡å‹æ˜¯è¾“å‡ºæ˜¯ <span class="math inline">\([0.1, 0.5,
0.4]\)</span>ï¼Œ</p>
<p>æ¨¡å‹åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œæ˜¯è®©æ¨¡å‹çš„è¾“å‡ºå»æ‹Ÿåˆè¯¥ one-hot
ç»“æœï¼Œè®¡ç®—æ–¹æ³•å¦‚äº¤å‰ç†µæŸå¤±ã€‚</p>
<h3 id="çŸ¥è¯†è’¸é¦çš„è®­ç»ƒæ–¹æ³•">çŸ¥è¯†è’¸é¦çš„è®­ç»ƒæ–¹æ³•</h3>
<p>2014 å¹´ï¼ŒHinton æå‡ºäº†<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/1503.02531">çŸ¥è¯†è’¸é¦</a>çš„æ¦‚å¿µï¼Œæ—¨åœ¨å°†å¤§æ¨¡å‹ï¼ˆæ•™å¸ˆï¼‰çš„çŸ¥è¯†ä¼ é€’ç»™å°æ¨¡å‹ï¼ˆå­¦ç”Ÿï¼‰ï¼Œä»¥æå‡å­¦ç”Ÿçš„èƒ½åŠ›ï¼Œå®ç°æ¨¡å‹å‹ç¼©çš„ç›®çš„ã€‚</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd3.png" /></p>
<p>æ­¥éª¤ï¼š</p>
<ol type="1">
<li><p>æ•™å¸ˆé€šè¿‡æŸä¸ªä»»åŠ¡è®­ç»ƒåï¼ˆç¡®ä¿æ•™å¸ˆæ˜¯æ”¶æ•›çš„ï¼‰ã€‚</p></li>
<li><p>å­¦ç”Ÿåœ¨è®­ç»ƒåŒæ ·ä»»åŠ¡æ—¶ï¼Œå¯¹äºåŒä¸€ä¸ªè¾“å…¥ï¼Œè€å¸ˆå’Œå­¦ç”Ÿä¼šæœ‰ä¸åŒçš„è¾“å‡ºï¼Œä»¤å­¦ç”Ÿçš„è¾“å‡ºå»æ‹Ÿåˆæ•™å¸ˆçš„è¾“å‡ºã€‚è®¡ç®—æ–¹æ³•å¦‚
<a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullbackâ€“Leibler
divergence</a>ï¼ˆKL æ•£åº¦ï¼‰ã€‚</p></li>
</ol>
<p>æ³¨ï¼šæ­¤æ—¶å­¦ç”Ÿçš„è¾“å‡ºåŒæ—¶ä¼šæ‹Ÿåˆ one-hot æ ‡ç­¾ï¼Œäº¤å‰ç†µã€‚</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kl_loss = nn.KLDivLoss(reduction=<span class="string">&quot;batchmean&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>stu_logits = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tea_logits = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">input</span> = F.log_softmax(stu_logits, dim=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target = F.softmax(tea_logits, dim=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = kl_loss(<span class="built_in">input</span>, target)</span><br></pre></td></tr></table></figure>
<p><strong>KL æ•£åº¦</strong></p>
<p>è¡¡é‡æ¦‚ç‡åˆ†å¸ƒ <span
class="math inline">\(Q\)</span>ï¼ˆå­¦ç”Ÿï¼‰ä¸ç¬¬äºŒä¸ªå‚è€ƒæ¦‚ç‡åˆ†å¸ƒ <span
class="math inline">\(P\)</span> ï¼ˆæ•™å¸ˆï¼‰æœ‰å¤šå¤§çš„ä¸åŒã€‚æˆ–è€…è¯´ï¼Œ<span
class="math inline">\(P\)</span> ç›¸å¯¹äº <span
class="math inline">\(Q\)</span> çš„ç›¸å¯¹ç†µ</p>
<p><span class="math display">\[
L(Q, P) = {\displaystyle D_{\text{KL}}(P\parallel Q)=\sum _{x\in
{\mathcal {X}}}P(x)\ \log \left({\frac {\ P(x)\ }{Q(x)}}\right).}
\]</span></p>
<p>å…¶ä¸­ï¼Œ<span class="math inline">\(P\)</span> å’Œ <span
class="math inline">\(Q\)</span> ä½œä¸ºæ¦‚ç‡åˆ†å¸ƒå¯ä»¥ç”¨ä¸€ä¸ªæ¸©åº¦ <span
class="math inline">\(T\)</span> æ¥ å¹³æ»‘/å°–é” åˆ†å¸ƒ</p>
<h3 id="çŸ¥è¯†è’¸é¦çš„å˜ç§">çŸ¥è¯†è’¸é¦çš„å˜ç§</h3>
<p>ç”±äºã€ŒçŸ¥è¯†ã€å¯ä»¥åŒ…å«å¤ªå¤šä¸œè¥¿ï¼Œæ‰€ä»¥åªè¦è·Ÿæ¨¡å‹ç›¸å…³çš„ä¸œè¥¿ï¼Œéƒ½å¯ä»¥è¢«è®¤ä¸ºæ˜¯çŸ¥è¯†ã€‚</p>
<ul>
<li><p>æœ¬èº«çš„æƒé‡ â†’ æ¨¡å‹èåˆ</p></li>
<li><p>ä¸­é—´å±‚è¾“å‡ºçš„ç‰¹å¾ â†’ é¢„è®­ç»ƒååšä¸‹æ¸¸çš„ Fine-tuning</p></li>
<li><p>æœ€åä¸€å±‚è¾“å‡ºçš„ logits â†’ ç»å…¸çŸ¥è¯†è’¸é¦</p></li>
<li><p>æ¨¡å‹è¾“å‡ºçš„ logits è¢«è§£ç æˆç¡¬æ ‡ç­¾ï¼ˆç±»åˆ«ä¿¡æ¯ã€æ–‡æœ¬â€¦ï¼‰ â†’
â€œéšå¼â€çš„çŸ¥è¯†è’¸é¦</p></li>
</ul>
<h3 id="çŸ¥è¯†è’¸é¦çš„-q-a">çŸ¥è¯†è’¸é¦çš„ Q &amp; A</h3>
<p>Qï¼šä¸ºä»€ä¹ˆæ˜¯ KL æ•£åº¦ï¼Ÿ</p>
<p>Aï¼šå¦‚æœæœ‰æ›´å¥½ã€æ›´ç®€å•çš„åº¦é‡æ–¹å¼ä¹Ÿå¯ä»¥æ›¿æ¢ï¼Œæ¯”å¦‚ <a
target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Wasserstein_metric">Wasserstein
metric</a></p>
<p>Qï¼šä¸ºä»€ä¹ˆæ˜¯å¤§æ¨¡å‹åšæ•™å¸ˆï¼Ÿ</p>
<p>Aï¼š</p>
<ul>
<li><p>ä»¥å‹ç¼©ä½œä¸ºå‡ºå‘ç‚¹ï¼Œå°±æ˜¯éœ€è¦æ›´å¥½æ•ˆæœçš„æ¨¡å‹æ¥å¼•å¯¼ã€‚</p></li>
<li><p>ä¹Ÿå¯ä»¥æ˜¯åŒç­‰å°ºå¯¸çš„æ¨¡å‹åšæ•™å¸ˆï¼Œåªè¦èƒ½å¤Ÿåœ¨æŸé¡¹ä»»åŠ¡ä¸Šè¡¨ç°è¶³å¤Ÿå¥½ã€‚å…³é”®è¯ï¼šè‡ªè’¸é¦</p></li>
</ul>
<p>Qï¼šé¢„å…ˆè®­ç»ƒä¸€ä¸ªæ•™å¸ˆæ¨¡å‹æœ‰ç‚¹éº»çƒ¦</p>
<p>Aï¼š</p>
<ul>
<li><p>æ¶ˆé™¤æ‰è¿™ä¸ªè¿‡ç¨‹ã€‚å°±ç±»ä¼¼äºåœ¨çº¿å­¦ä¹ ï¼Œå…³é”®è¯ï¼šåœ¨çº¿è’¸é¦ã€‚</p></li>
<li><p>å¤§æ¨¡å‹é€šå¸¸æ”¶æ•›çš„ä¼šæ¯”å°æ¨¡å‹æ›´å¿«ã€‚ï¼ˆåŒæ—¶è®­ç»ƒï¼Œå¹¶ä¸æ˜¯ä¸è®­ç»ƒï¼‰</p></li>
<li><p>æ•™å¸ˆæ¨¡å‹é€šå¸¸ä¼šè¢«â€œå¥½å¿ƒäººâ€æä¾›å‡ºæ¥ï¼Œåšçš„å·¥ä½œä¸éœ€è¦å¤ªå¤š</p></li>
</ul>
<p>Qï¼šä¸ºä»€ä¹ˆç”¨æœ€åä¸€å±‚çš„ logitsï¼Œä¸­é—´å±‚çš„è¡Œä¸è¡Œï¼Ÿ</p>
<p>Aï¼š</p>
<ul>
<li><p>å¯ä»¥ç”¨ä¸­é—´å±‚ï¼Œä½†ä¼šæœ‰äº›é™åˆ¶ï¼Œéœ€è¦å¼•å…¥é¢å¤–çš„ä¼˜åŒ–ã€‚å…³é”®è¯ï¼šç‰¹å¾è’¸é¦</p></li>
<li><p>æ¶æ„å¯èƒ½ä¸ä¸€æ ·</p></li>
<li><p>é€‰å“ªäº›å±‚è’¸é¦å“ªäº›å±‚ã€‚æ¯”å¦‚æ•™å¸ˆæœ‰20å±‚ï¼Œå­¦ç”Ÿæœ‰10å±‚ï¼Œå“ªäº›å±‚çš„è¾“å‡ºä½œä¸ºæ‹Ÿåˆå¯¹è±¡æ˜¯ä¸å¥½ç¡®å®šçš„ã€‚</p></li>
</ul>
<p>Qï¼šå…¶ä»– tricks</p>
<p>Aï¼š</p>
<ul>
<li><p>æ¸©åº¦ temperatureï¼Œè¶…å‚æ•°ã€‚</p></li>
<li><p>KL çš„æƒé‡ç³»æ•°</p></li>
<li><p>è’¸é¦çš„è®¡ç®—æ–¹æ³•</p></li>
</ul>
<p>â€¦â€¦</p>
<h2 id="åœ¨-llm-ä¸­çš„çŸ¥è¯†è’¸é¦"><a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2402.13116">åœ¨ LLM ä¸­çš„çŸ¥è¯†è’¸é¦</a></h2>
<p>ç”±äºç®—åŠ›ã€æ•°æ®ç­‰åŸå› ï¼Œå¼€æºæ¨¡å‹å¾€å¾€å¼±äºé—­æºæ¨¡å‹ã€‚çŸ¥è¯†è’¸é¦æ˜¯ä¸€ç§å¯èƒ½ç¼©å°è¿™ä¸¤è€…å·®è·çš„æ‰‹æ®µã€‚</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd4.png" /></p>
<h3 id="ä¸‰ç§æ–¹æ³•">ä¸‰ç§æ–¹æ³•</h3>
<ul>
<li><p>é’ˆå¯¹ç‰¹å®šé¢†åŸŸï¼Œå›ºå®šçŸ¥è¯†ç§å­(å‡ç»ƒå‡ºè‹¥å¹²ç‰¹å®šçš„é—®é¢˜ï¼‰ï¼Œç”¨é—­æºæ¨¡å‹ç”Ÿæˆæ›´å¤šçš„æ•°æ®ï¼ˆéšå¼çš„çŸ¥è¯†è’¸é¦ï¼‰ã€‚ï¼ˆPASSï¼‰</p></li>
<li><p>æ¨¡å‹å‹ç¼©ï¼ˆPASSï¼‰</p></li>
<li><p>è‡ªæˆ‘æå‡ï¼ˆself-improvementï¼‰</p>
<ul>
<li><p>SFT æ¨¡å‹ç”Ÿæˆæ•°æ®æ ‡æ³¨åä½œä¸º DPO çš„çš„è®­ç»ƒæ•°æ®ï¼Œ<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2305.18290">https://arxiv.org/abs/2305.18290</a></p></li>
<li><p>ç”¨å¼€æºæ¨¡å‹ç”Ÿæˆ Q &amp; A ä½œä¸º SFT è®­ç»ƒæ•°æ®ï¼Œ <a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.08464">https://arxiv.org/abs/2406.08464</a></p></li>
</ul></li>
</ul>
<p>æ³¨ï¼šè‡ªæˆ‘æå‡åœ¨è’¸é¦é‡Œé¢åˆè¢«å«åšè‡ªè’¸é¦</p>
<h2 id="llm-sft-ä¸­è’¸é¦çš„ç±»åˆ«">LLM SFT ä¸­è’¸é¦çš„ç±»åˆ«</h2>
<p>LLMï¼šåœ¨è¶…å¤šåˆ†ç±»ä»»åŠ¡ä¸Šè¿›è¡Œè®­ç»ƒçš„å¤§å°ºå¯¸æ¨¡å‹ã€‚æ‰€ä»¥ï¼Œç›¸è¾ƒäºç»å…¸çŸ¥è¯†è’¸é¦ï¼Œä¼šæœ‰ä¸€äº›ä¸åŒã€‚</p>
<p>$p(x) $ è¡¨ç¤ºæ•™å¸ˆè¾“å‡ºï¼Œ$q(x) $ è¡¨ç¤ºå­¦ç”Ÿè¾“å‡º</p>
<ul>
<li><p>Forward KDï¼ˆç»å…¸è’¸é¦ï¼‰: <span
class="math display">\[D_{\text{KL}}(P\parallel Q)=\sum_x p(x) \log
[\frac{p(x)}{q(x)}]\]</span></p></li>
<li><p>Reverse KD: <span class="math display">\[D_{\text{KL}}(Q\parallel
P)=\sum_x q(x) \log [\frac{q(x)}{p(x)}]\]</span></p></li>
<li><p>JS Divergence: <span
class="math display">\[\frac{1}{2}(D_{\text{KL}}(P\parallel
Q)+D_{\text{KL}}(Q\parallel P))\]</span></p></li>
</ul>
<p>å…¶ä»–ï¼šå¯¹äºæ¨¡å‹ä¸­é—´å±‚çš„è¾“å‡ºè¿›è¡Œå¯¹é½</p>
<h2 id="reverse-kd">Reverse KD</h2>
<p>æ¥æºï¼š<a
target="_blank" rel="noopener" href="https://agustinus.kristia.de/techblog/2016/12/21/forward-reverse-kl/">https://agustinus.kristia.de/techblog/2016/12/21/forward-reverse-kl/</a></p>
<h3 id="å›é¡¾-kl-æŸå¤±">å›é¡¾ KL æŸå¤±</h3>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd5.png" /></p>
<p>è“çº¿ï¼ˆæ•™å¸ˆï¼‰æ˜¯ p(x)ï¼Œç»¿çº¿ï¼ˆå­¦ç”Ÿï¼‰æ˜¯ q(x)ã€‚KL æ•£åº¦çš„å°±æ˜¯è®¡ç®—
åŠ æƒå¹³å‡å€¼ã€‚</p>
<p><span class="math display">\[
\sum_x p(x) \log [\frac{p(x)}{q(x)}]
\]</span></p>
<p>é‚£ä¹ˆï¼Œå‡ºç°ä¸‹é¢çš„æƒ…å†µæ—¶ï¼ŒKL æ•£åº¦å°±ä¼šç‰¹åˆ«å¤§ï¼ˆè“çº¿ä¸¤ä¸ªå‡¸çš„åŒºåŸŸï¼‰</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd6.png" /></p>
<p>ç»¿çº¿æ‹Ÿåˆè“çº¿ä¹‹åï¼Œä¼šè®©ç»¿çº¿åˆ†å¸ƒçš„æ›´å¹¿æ³›ï¼ˆåŸæ¥æ²¡æœ‰å€¼çš„åœ°æ–¹æœ‰å€¼äº†ï¼‰ã€‚</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd7.png" /></p>
<p>å¯¼è‡´ä¸åº”è¯¥æœ‰å€¼çš„åœ°æ–¹æœ‰å€¼ï¼Œå¯¹äºæŸäº›è¾“å…¥xï¼Œæœ‰äº›ç±»åˆ«æ¦‚ç‡åº”è¯¥ä¸º 0ã€‚</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd8.gif" /></p>
<h3 id="æ–¹æ³•">æ–¹æ³•</h3>
<p>Reverse KL å°±æ˜¯å°† <span class="math inline">\(p\)</span>ã€<span
class="math inline">\(q\)</span> ä½ç½®äº’æ¢ï¼Œ</p>
<p><span class="math display">\[
\sum_x q(x) \log [\frac{q(x)}{p(x)}]
\]</span></p>
<p>æ­¤æ—¶ï¼Œå†çœ‹åˆšåˆšè¿™å¼ å›¾</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd9.png" /></p>
<p><span class="math inline">\(q(x)\)</span>
æ­¤æ—¶ä½œä¸ºæƒé‡ï¼Œä¼šè®©ç»¿çº¿å‡¸å‡ºæ¥çš„åœ°æ–¹æ›´å‡¹ä¸€äº›ã€‚ä½†ä¸ä¼šå­¦ä¹ è“è‰²å³ä¾§å‡¸çš„åœ°æ–¹ã€‚</p>
<p>åœ¨ LLM ä¸Šï¼Œç±»åˆ«æ ‡ç­¾ç‰¹åˆ«å¤šï¼ŒForward KL ä¼šä½¿å¾—å„ä¸ª token id
æ›´åŠ â€œå‡åŒ€â€ã€‚</p>
<ul>
<li><p>å¥½ï¼šå¯ä»¥å¢åŠ å¤šæ ·æ€§</p></li>
<li><p>åï¼šå­¦ç”Ÿå¯èƒ½ä¼šå­¦åˆ°ä¸€äº›ä½è´¨é‡çš„æ¦‚ç‡æ ‡ç­¾ï¼Œä»è€Œå¯¼è‡´ç”Ÿæˆå¹»è§‰å’Œä½è´¨é‡æ–‡æœ¬</p></li>
</ul>
<p>Reverse KL</p>
<ul>
<li><p>å¥½ï¼šé¿å…äº†ä½è´¨é‡æ ‡ç­¾</p></li>
<li><p>åï¼šè¿‡äºç›¸ä¿¡å­¦ç”Ÿçš„é¢„æµ‹ï¼Œå¦‚æœå­¦ç”Ÿçš„é¢„æµ‹ä¸æ˜¯æœ€ä¼˜çš„ï¼ˆå³ç»¿è‰²åœ¨è“è‰²çš„ç¬¬äºŒä¸ªå‡¸å‡ºï¼‰ï¼Œä¼šå˜å·®</p></li>
</ul>
<h3 id="å°ç»“">å°ç»“</h3>
<ul>
<li><p>ç›‘ç£å­¦ä¹ ç”¨ Forward KL â†’ SFT æ¨¡å‹åšæ•™å¸ˆ</p></li>
<li><p>å¼ºåŒ–å­¦ä¹ ç”¨ Reverse KL â†’ DPO è®­ç»ƒæ¨¡å‹åšå­¦ç”Ÿ</p></li>
</ul>
<p>Qï¼šä¸ºä»€ä¹ˆ RL ç”¨ Reverse KLï¼Ÿ</p>
<p>Aï¼šå¼ºåŒ–å­¦ä¹ åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œä¼šâ€œå…‹éš†â€æ¨¡å‹å¹¶æ›´æ–°åŸæ¥çš„æ¨¡å‹ã€‚å¦‚æœç”¨ Forward
KLï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ KL å€¼è¿‡é«˜ä¼šå¯¼è‡´æ¨¡å‹ä¸æ”¶æ•›ã€‚è€Œ Reverse KL
ä¸€ç§æ›´åŠ ç¨³å¦¥çš„æ–¹å¼ï¼Œèƒ½å¤Ÿä¿è¯ KL
æ•£åº¦è¶³å¤Ÿå°ã€‚ä¸”ç”±äºæ¨¡å‹æ˜¯å…‹éš†çš„ï¼Œæ‰€ä»¥æ•™å¸ˆå’Œå­¦ç”Ÿçš„é¢„æµ‹ç»“æœä¼šæ¯”è¾ƒç›¸åƒï¼Œå³ä¸ä¼šå‡ºç°å­¦ç”Ÿé¢„æµ‹åœ¨æ•™å¸ˆçš„æ¬¡ä¼˜ä¸Šã€‚</p>
<p><a
target="_blank" rel="noopener" href="https://www.reddit.com/r/reinforcementlearning/comments/kcqbhv/hi_all_can_anyone_please_help_me_understand_how/">https://www.reddit.com/r/reinforcementlearning/comments/kcqbhv/hi_all_can_anyone_please_help_me_understand_how/</a></p>
<p><strong>Summary</strong></p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd10.png" /></p>
<p>Jensonâ€“Shannon (JS) Divergence</p>
<p><span class="math display">\[
\frac{1}{2}(D_{\text{KL}}(P\parallel Q)+D_{\text{KL}}(Q\parallel P)ï¼‰
\]</span></p>
<p><span class="math display">\[
\frac{1}{2}(\sum p(x) \log\frac{2p(x)}{p(x)+q(x)} + \sum
q(x)\log\frac{2q(x)}{p(x)+q(x)})
\]</span></p>
<p>KL æ˜¯éå¯¹ç§°çš„ï¼Œ JS æŠŠä¸¤ç§åˆ†å¸ƒçš„ KL
éƒ½ç®—ä¸€éï¼Œä»¥æ­¤å–å¾—äº†å¯¹ç§°çš„ç»“æœã€‚</p>
<p>å¼•å…¥å¯¹ç§°æ€§å¸¦æ¥çš„ç¼ºç‚¹ï¼š</p>
<ul>
<li><p>è®¡ç®—å¤æ‚åº¦é«˜ï¼šè®¡ç®—äº†ä¸¤æ¬¡ KL Divergence</p></li>
<li><p>æ•°å€¼ç¨³å®šæ€§å·®ï¼šå¦‚æœ P å’Œ Q
çš„æ¦‚ç‡åˆ†å¸ƒå·®å¼‚è¾ƒå¤§ï¼Œå¯èƒ½ä¼šå‡ºç°é›¶æˆ–éå¸¸å°çš„æ¦‚ç‡å€¼ã€‚æ¯”å¦‚ p(x) æŸé¡¹ä¸º
0</p></li>
</ul>
<p>ä¸”éå¯¹ç§°æ€§æœ‰æ—¶å€™ä¸æ˜¯ä¸€ç§ç¼ºç‚¹ï¼Œæ˜¯ä¸€ä¸ª featureã€‚</p>
<p><strong>éå¯¹ç§°æ€§</strong>å¸¦æ¥äº†ä»€ä¹ˆï¼šä¿ç•™ã€Œé¢„æµ‹åˆ†å¸ƒã€åˆ°ã€Œç›®æ ‡åˆ†å¸ƒã€çš„æ–¹å‘ä¿¡æ¯</p>
<ul>
<li>åœ¨çœŸå®åˆ†å¸ƒ P ä¸­å¸¸è§çš„äº‹ä»¶ï¼Œå¦‚æœåœ¨é¢„æµ‹åˆ†å¸ƒ Q
ä¸­çš„æ¦‚ç‡è¾ƒä½ã€‚æœ‰åŠ©äºæ¨¡å‹ä¼˜åŒ–ã€‚</li>
</ul>
<p>æ³¨ï¼šè¿˜æœ‰ä¸€ä¸ª <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2302.13344">TVD</a>
æ–¹æ³•ï¼Œç±»ä¼¼äº JS åº¦é‡ï¼Œä½†å®ƒç”¨ L1 èŒƒæ•°ä»£æ›¿äº† KL</p>
<h2 id="forward-kdç»å…¸è’¸é¦">Forward KDï¼ˆç»å…¸è’¸é¦ï¼‰</h2>
<p>Baby Llamaï¼š<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2308.02019">https://arxiv.org/abs/2308.02019</a></p>
<p>Less is Moreï¼š<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2210.01351">https://arxiv.org/abs/2210.01351</a>
ï¼ˆBertï¼‰</p>
<p>åˆ†ä¸¤é˜¶æ®µè’¸é¦</p>
<ul>
<li><p>Stage 1: è’¸é¦è®­ç»ƒæœ€åä¸€å±‚</p></li>
<li><p>Stage 2: è’¸é¦è®­ç»ƒä¸­é—´å±‚ï¼Œæ¯å±‚æœ‰ä¸€ä¸ª loss</p></li>
</ul>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd11.png" /></p>
<h2 id="reverse-kd-1">Reverse KD</h2>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2306.08543">è®ºæ–‡</a></p>
<p><a
target="_blank" rel="noopener" href="https://github.com/microsoft/LMOps/tree/main/minillm">è®ºæ–‡ä»£ç </a></p>
<h3 id="åŠ¨æœº">åŠ¨æœº</h3>
<p>void regions (ç©ºæ´åŒºåŸŸ)</p>
<p>where ğ‘â€² can be real data distribution (word-level KD) or teacher
distribution ğ‘ (sequence-level KD). Though widely used, KL[ğ‘||ğ‘ğœƒ] has
been shown to overestimate the void regions of ğ‘ in language generation
tasks when ğ‘ğœƒ is insufficiently expressive to cover all the modes of
ğ‘â€²</p>
<p>. KD for LLMs fits the case because LLMs perform various tasks in a
generative manner, such that the low-capacity student models cannot
perfectly imitate the complex language generation distribution of the
teacher models or humans.</p>
<ul>
<li><p>æ¨¡å¼è¦†ç›–é—®é¢˜ï¼šçœŸå®æ•°æ®ï¼ˆæˆ–æ•™å¸ˆæ¨¡å‹ï¼‰çš„åˆ†å¸ƒ ( p )
å¯èƒ½åŒ…å«å¾ˆå¤šå¤æ‚å’Œå¤šæ ·çš„è¯­è¨€æ¨¡å¼ï¼Œè€Œå­¦ç”Ÿæ¨¡å‹ ( $q_{} $ )
å—é™äºæ¨¡å‹å¤æ‚åº¦æˆ–è®­ç»ƒæ•°æ®çš„å±€é™ï¼Œå¯èƒ½æ— æ³•æ¶µç›–æ‰€æœ‰æ¨¡å¼ã€‚</p></li>
<li><p>ç”Ÿæˆè´¨é‡é—®é¢˜ï¼šè¿™ä¼šä½¿å¾—è®­ç»ƒè¿‡ç¨‹ä¸­æ›´å¤šå…³æ³¨è¿™äº›éš¾ä»¥è¦†ç›–çš„æ¨¡å¼ï¼Œå¯¼è‡´å­¦ç”Ÿæ¨¡å‹æ— æ³•æœ‰æ•ˆæé«˜åœ¨å¸¸è§æ¨¡å¼ä¸Šçš„ç”Ÿæˆè´¨é‡ã€‚</p></li>
</ul>
<h3 id="æ–¹æ³•-1">æ–¹æ³•</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">tea_probs = F.softmax(tea_logits, dim=-<span class="number">1</span>, dtype=torch.float32)</span><br><span class="line">stu_probs = F.log_softmax(logits, dim=-<span class="number">1</span>, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ ‡å‡† KD</span></span><br><span class="line">kd_loss = (tea_probs*(tea_probs.log()-stu_probs)).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># åŒ–ç®€</span></span><br><span class="line">kd_loss = (tea_probs*std_probs).<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½æ–¹å·®ä¼°è®¡ï¼Œa low-variance estimation KD</span></span><br><span class="line"><span class="comment"># http://joschu.net/blog/kl-approx.html</span></span><br><span class="line">log_ratio = (stu_probs - tea_probs.log())</span><br><span class="line">kd_loss = log_ratio.<span class="built_in">float</span>().exp() - <span class="number">1</span> - log_ratio</span><br></pre></td></tr></table></figure>
<h4 id="approximating-kl-divergence"><a
target="_blank" rel="noopener" href="http://joschu.net/blog/kl-approx.html">Approximating KL
Divergence</a></h4>
<p>æ ‡å‡†çš„ KD</p>
<p><span class="math display">\[
KL[q, p] = \sum_x q(x) \log [\frac{q(x)}{p(x)}] = E_{ x \sim q}[\log
\frac{q(x)}{p(x)} ]
\]</span></p>
<p>ç”±äºç²¾ç¡®è®¡ç®—éœ€è¦èŠ±è´¹æ›´å¤šçš„å†…å­˜ï¼Œæ‰€ä»¥æœŸæœ›å¯¹é½è¿›è¡Œä¼°è®¡ï¼Œä»è€Œå‡å°‘è®¡ç®—é‡ã€‚</p>
<p><strong>Step 1</strong></p>
<p>ä¸€ç§ç›´æ¥çš„æ€è·¯æ˜¯ç›´æ¥å»æ‰æœ€å¤–é¢çš„ <span
class="math inline">\(q(x)\)</span>ï¼Œæ¼”å˜æˆäº†</p>
<p><span class="math display">\[
-\log\frac{p(x)}{q(x)}
\]</span></p>
<p>å› ä¸ºèˆå»äº†ç³»æ•°ï¼Œå®ƒä¼šä½¿å¾—æ–¹å·®å˜é«˜</p>
<p><strong>Step 2</strong></p>
<p>åŠ ä¸Šå¹³æ–¹ï¼Œé™ä½æ–¹å·®</p>
<p><span class="math display">\[
\frac{1}{2}(\log\frac{p(x)}{q(x)})^2
\]</span></p>
<p><strong>Step 3</strong></p>
<p>kd12ä¾èµ–æ•°å­¦èƒŒæ™¯å…¬å¼</p>
<p><span class="math display">\[
\log(x)\leq x-1
\]</span></p>
<p>ä½†ä¿è¯è¯¥å…¬å¼ <span class="math inline">\(&gt;= 0\)</span>
æ—¶ï¼Œå°±æœ‰</p>
<p><span class="math display">\[
(x-1) - \log(x) \geq 0
\]</span></p>
<p>æŠŠè¿™é‡Œ <span class="math inline">\(x\)</span> æ¢æˆ <span
class="math inline">\(p(x) / q(x)\)</span> å°±å¾—åˆ°äº†ä»£ç çš„è®¡ç®—æ–¹æ³•</p>
<h4 id="optimization-with-policy-gradient">Optimization with Policy
Gradient</h4>
<p>ä¼˜åŒ–å…¬å¼</p>
<p><span
class="math display">\[\theta=\arg\min\limits_{\theta}\mathcal{L}(\theta)=\arg\min\limits_{\theta}\mathrm{KL}[q_{\theta}||p]=\arg\operatorname*{min}_{\theta}\left[-\operatorname*{lim}_{x\sim
p_{\infty},y\sim
q_{\theta}}\log{\frac{p(y|x)}{q_{\theta}(y|x)}}\right]\]</span></p>
<p>Policy Gradient Theore æ±‚å¯¼</p>
<p><span
class="math display">\[\nabla{\mathcal{L}}(\theta)=-\operatorname*{\mathbb{E}}_{\mathbf{x}\sim
p_{\mathbf{x}},y\sim
q_{\theta}(\,\cdot\,|\mathbf{x})}\sum_{t=1}^T(R_{t}-1)\nabla\log
q_{\theta}(y_{t}|\mathbf{y}_{&lt;t},\mathbf{x}),\]</span></p>
<p>å…¶ä¸­ï¼Œ$R_t $ æ˜¯æ¯ä¸€æ­¥ç”Ÿæˆçš„ç´¯ç§¯ï¼Œè¡¡é‡æ¯ä¸€æ­¥çš„ç”Ÿæˆè´¨é‡</p>
<p><span
class="math display">\[R_{t}=\sum_{t^{\prime}=t}^{T}\log\,\frac{p(y_{t^{\prime}}|y_{&lt;t^{\prime}},\mathbf{x})}{q_{\theta}(y_{t^{\prime}}|y_{&lt;t^{\prime}},\mathbf{x})}\]</span></p>
<p>ä¸‰ä¸ªä¼˜åŒ–</p>
<p><strong>ä¼˜åŒ–1ï¼šSingle-Step Decomposition</strong></p>
<p>å•æ­¥ç”Ÿæˆçš„è´¨é‡éƒ½å¾ˆé‡è¦ï¼Œæ‰€ä»¥æŠŠå•æ­¥ç”Ÿæˆå’Œç´¯ç§¯ç”Ÿæˆæ‹†å¼€ï¼Œå¹¶ç›´æ¥è®¡ç®—å•æ­¥ç”Ÿæˆçš„æ¢¯åº¦</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd15.png" /></p>
<p><strong>ä¼˜åŒ–2ï¼šTeacher-Mixed Sampling</strong></p>
<p>æ•™å¸ˆç”Ÿæˆçš„å¥å­å¯èƒ½ä¼šé‡å¤ï¼Œæ‰€ä»¥ç”¨æ•™å¸ˆå’Œå­¦ç”Ÿçš„æ··åˆåˆ†å¸ƒæ¥ä»£æ›¿åŸæœ‰çš„æ•™å¸ˆåˆ†å¸ƒ
(px)ï¼Œå¹¶ä¸”ç”¨ $$ æ¥æ§åˆ¶å¼ºåº¦ã€‚</p>
<p><span
class="math display">\[\tilde{p}(y_{t}\,|\,y_{&lt;\,t},x)=\alpha\cdot
p(y_{t}\,|\,y_{&lt;\,t},x)+(1-\alpha)\cdot
q_{\theta}(y_{t}\,|\,y_{&lt;\,t},x),\]</span></p>
<p>å³ï¼Œ</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd17.png" /></p>
<p><strong>ä¼˜åŒ–3ï¼šLength Normalization</strong></p>
<p>æ¨¡å‹ä¼šä¸ºäº†æ›´ä½çš„æŸå¤±ï¼Œå®¹æ˜“â€œå·æ‡’â€ç”ŸæˆçŸ­æ–‡æœ¬ã€‚ä¸ºäº†æ¶ˆé™¤é•¿åº¦å½±å“ï¼ŒåŠ å…¥é•¿çŸ­æ–‡æœ¬çš„å½’ä¸€åŒ–æ“ä½œ</p>
<p><span
class="math display">\[R_{t+1}^{\mathrm{Norm}}=\frac{1}{T-t-1}\sum_{t^{\prime}=t+1}^{T}\log\frac{p(y_{t^{\prime}}|y_{&lt;t^{\prime}},\mathbf{x})}{q_{\theta}(y_{t^{\prime}}|y_{&lt;t^{\prime}},\mathbf{x})}.\]</span></p>
<p>ç»¼ä¸Šï¼Œæœ€åçš„å…¬å¼ä¸º</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd19.png" /></p>
<p>ç»“æœ</p>
<ul>
<li><p>SFT w/o KDï¼šæ ‡å‡† SFT</p></li>
<li><p>KDï¼š æ ‡å‡† SFT åŠ å…¥ KD æŸå¤±ï¼Œåˆç§°ä¸º Word-Level KD</p></li>
<li><p>SeqKDï¼šå¥å­çº§åˆ«çš„KDï¼Œåœ¨æ•™å¸ˆæ¨¡å‹ç”Ÿæˆçš„æ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒ</p></li>
<li><p>MINILLMï¼šæå‡ºçš„æ–¹æ³•ï¼Œreverse KD + PPO + è‹¥å¹² tricks</p></li>
</ul>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd20.png" /></p>
<h3 id="æ¶ˆèå®éªŒ">æ¶ˆèå®éªŒ</h3>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd21.png" /></p>
<h2 id="è§£è€¦çŸ¥è¯†è’¸é¦">è§£è€¦çŸ¥è¯†è’¸é¦</h2>
<p><a
target="_blank" rel="noopener" href="https://openreview.net/pdf/73503af2a5797fb9046f0fa702c3a4d5ea5ceaf8.pdf">è®ºæ–‡</a></p>
<h3 id="èƒŒæ™¯çŸ¥è¯†">èƒŒæ™¯çŸ¥è¯†</h3>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2203.08679">è®ºæ–‡</a></p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd22.png" /></p>
<p>æŠŠ KD æ‹†æˆäº†ä¸¤ä¸ªéƒ¨åˆ†ï¼ŒDKD+TKDã€‚å…¶ä¸­ï¼Œ</p>
<ul>
<li><p>TKD æŒ‡çš„æ˜¯ ground truth å¯¹åº”çš„ logits ï¼ˆTCKDï¼‰</p></li>
<li><p>DKD æŒ‡çš„æ˜¯é ground truth å¯¹åº”çš„ logitsï¼ˆNCKDï¼‰</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>kl_loss = nn.KLDivLoss(reduction=<span class="string">&quot;batchmean&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>stu_logits = torch.randn(<span class="number">3</span>, <span class="number">5</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tea_logits = torch.randn(<span class="number">3</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
<p>ç»å…¸ KD</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">input</span> = F.log_softmax(stu_logits, dim=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target = F.softmax(tea_logits, dim=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>loss = kl_loss(<span class="built_in">input</span>, target)</span><br></pre></td></tr></table></figure>
<p>DKD + TKD <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>dkd_tea = F.softmax(tea_logits - <span class="number">1000</span> * gt_mask, dim=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dkd_stu = F.log_softmax(stu_logits - <span class="number">1000</span> * gt_mask, dim=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>dkd_loss = kl_loss(dkd_stu, dkd_tea)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>tea_probs = F.softmax(tea_logits)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>stu_probs = F.softmax(stu_logits)</span><br><span class="line"><span class="comment"># å‡è®¾ tea_probs = [0.4, 0.3, 0.3], stu_probs = [0.2, 0.6, 0.2]</span></span><br><span class="line"><span class="comment"># target ä¸ºç¬¬ 0 ä¸ªä½ç½®</span></span><br><span class="line"><span class="comment"># tkd_loss  ä¸º [0.4, 0.6] å’Œ [0.2, 0.8] å®ƒä»¬çš„ kl æ•£åº¦</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>output = w1*dkd_loss + w2*tkd_loss</span><br></pre></td></tr></table></figure></p>
<p>TKDï¼šæ ·æœ¬çš„â€œéš¾åº¦â€ä¿¡æ¯</p>
<blockquote>
<p>transfers the knowledge concerning the â€œdifficultyâ€ of training
samples.</p>
</blockquote>
<p>DKDï¼šæ ·æœ¬çš„â€œæš—çŸ¥è¯†â€</p>
<blockquote>
<p>is the prominent reason why logit distillation works but is greatly
suppressed.</p>
</blockquote>
<p><strong>ç»“æœ</strong></p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd23.png" /></p>
<p>ç‰¹å¾è’¸é¦ï¼šåœ¨æ¨¡å‹ä¸­é—´å±‚å¢åŠ åº¦é‡çš„æŸå¤±å‡½æ•°</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd24.png" /></p>
<p><a
target="_blank" rel="noopener" href="https://github.com/megvii-research/mdistiller/blob/master/mdistiller/distillers/DKD.py">ä»£ç </a></p>
<h3 id="å‘ç°">å‘ç°</h3>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd25.png" /></p>
<ul>
<li><p>å¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œé ground truth
ï¼ˆDKDï¼‰è’¸é¦æ•ˆæœä¼šä¼˜äºå…¶ä»–æ•ˆæœ</p></li>
<li><p>å°éƒ¨åˆ†æƒ…å†µï¼ˆéš¾å­¦çš„æƒ…å†µï¼‰ï¼ŒåŠ ä¸Š TKD ä¼šæ›´å¥½ã€‚</p></li>
</ul>
<h3 id="æ–¹æ³•-2">æ–¹æ³•</h3>
<p>hard to learn çš„å®šä¹‰</p>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd26.png" /></p>
<p>å¯¹äºæ¯ä¸ªè¦é¢„æµ‹çš„ tokenï¼Œæ•™å¸ˆæ¨¡å‹ä¼šè¾“å‡ºä¸€ä¸ª logitsï¼Œgt è¡¨ç¤º ground
truth çš„ tokenï¼Œè€Œ è¡¨ç¤ºé ground truth çš„ tokenã€‚</p>
<p>è¡¥å……ï¼Œ</p>
<ul>
<li><p><span class="math inline">\([0.1,0.9]\)</span> å¥½å­¦</p></li>
<li><p><span class="math inline">\([0.5,0.5]\)</span> ä¸å¥½å­¦</p></li>
</ul>
<p>æ‰€ä»¥ï¼Œè¿™é‡Œæ˜¯å¯¹ logits å– softmax åçš„ç»“æœï¼ˆæ¦‚ç‡ï¼‰ï¼ŒUNC ä¸º é ground
truth token çš„ æ¦‚ç‡å€¼ä¹‹å’Œã€‚å…¶è¶Šå¤§åˆ™è¡¨ç¤ºè¿™ä¸ªè¶Šéš¾å­¦ã€‚</p>
<p>é€šè¿‡ UNC è¿™ä¸ªæŒ‡æ ‡å˜æˆæˆ TKD çš„ç³»æ•°ï¼Œè‡ªé€‚åº”çš„è®­ç»ƒã€‚</p>
<h3 id="ç»“æœ">ç»“æœ</h3>
<p><img
src="https://raw.githubusercontent.com/wnma3mz/blog_posts/master/imgs/kdinLLM/kd27.png" /></p>
<h2 id="å†™åœ¨æœ€å">å†™åœ¨æœ€å</h2>
<p>ã€Œä½ å¥½ï¼Œã€åé¢å¯ä»¥æ¥ã€Œä¸–ç•Œã€ï¼Œå¯ä»¥æ¥ã€ŒåŒ—äº¬ã€ã€‚</p>
<p>åœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œæœ‰ä¸¤æ¡æ ·æœ¬ã€Œä½ å¥½ï¼Œä¸–ç•Œã€å’Œã€Œä½ å¥½ï¼ŒåŒ—äº¬ã€ã€‚è¿™ä¸ªæ—¶å€™ï¼Œå¯¹äºä»»æ„ä¸€æ¡æ ·æœ¬ï¼Œã€Œä¸–ç•Œã€å’Œã€ŒåŒ—äº¬ã€çš„
one-shot ç¼–ç æ˜¯ [0, 1, 0] å’Œ [0, 0, 1] ã€‚</p>
<p>ä¸¤ä¸ªä¸ç¡®å®šï¼š</p>
<ul>
<li><p>æ— æ³•æ§åˆ¶æ¨¡å‹æœ€ç»ˆå­¦åˆ°çš„æ¦‚ç‡åˆ†å¸ƒæ˜¯ä»€ä¹ˆæ ·çš„</p></li>
<li><p>ä¸çŸ¥é“æœ€ä½³åˆ†å¸ƒæ˜¯ä»€ä¹ˆ</p></li>
</ul>
<p>çŸ¥è¯†è’¸é¦ï¼š</p>
<ul>
<li><p>å¯ä»¥æ›´å®¹æ˜“æ§åˆ¶å­¦ç”Ÿæ¨¡å‹å­¦ä¹ å“ªç§åˆ†å¸ƒ</p></li>
<li><p>æ•™å¸ˆæ¨¡å‹ä¼šè¾“å‡ºä¸€ç§æ›´å¥½çš„åˆ†å¸ƒ</p></li>
</ul>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>æœ¬æ–‡ä½œè€…ï¼š </strong>wnma3mz
  </li>
  <li class="post-copyright-link">
    <strong>æœ¬æ–‡é“¾æ¥ï¼š</strong>
    <a href="https://wnma3mz.github.io/2024/08/08/Knowledge-Distillation-in-LLM/" title="Knowledge Distillation in LLM">https://wnma3mz.github.io/2024/08/08/Knowledge-Distillation-in-LLM/</a>
  </li>
  <li class="post-copyright-license">
    <strong>ç‰ˆæƒå£°æ˜ï¼š </strong>æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/zh-Hans" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> è®¸å¯åè®®ã€‚è½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/hexo_blog/tags/NLP/" rel="tag"># NLP</a>
              <a href="/hexo_blog/tags/LLM/" rel="tag"># LLM</a>
              <a href="/hexo_blog/tags/knowledge-distillation/" rel="tag"># knowledge distillation</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/hexo_blog/2024/07/21/LLM%20%E7%A1%AC%E4%BB%B6%E6%AF%94%E4%BB%B7/" rel="prev" title="LLM ä¸åŒç¡¬ä»¶æ¨ç†é€Ÿåº¦å¯¹æ¯”">
      <i class="fa fa-chevron-left"></i> LLM ä¸åŒç¡¬ä»¶æ¨ç†é€Ÿåº¦å¯¹æ¯”
    </a></div>
      <div class="post-nav-item">
    <a href="/hexo_blog/2024/09/05/LLM%E6%8E%A8%E7%90%86%E7%9B%B8%E5%85%B3%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F/" rel="next" title="LLMçš„æ¨ç†ç›¸å…³è®¡ç®—å…¬å¼">
      LLMçš„æ¨ç†ç›¸å…³è®¡ç®—å…¬å¼ <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          æ–‡ç« ç›®å½•
        </li>
        <li class="sidebar-nav-overview">
          ç«™ç‚¹æ¦‚è§ˆ
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#outlines"><span class="nav-text">Outlines</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E6%98%AF%E4%BB%80%E4%B9%88"><span class="nav-text">çŸ¥è¯†è’¸é¦æ˜¯ä»€ä¹ˆ</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%8E%E4%B9%88%E5%81%9A%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F"><span class="nav-text">æ€ä¹ˆåšçŸ¥è¯†è’¸é¦</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%8F%E5%85%B8%E7%9A%84%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95"><span class="nav-text">ç»å…¸çš„è®­ç»ƒæ–¹æ³•</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E7%9A%84%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95"><span class="nav-text">çŸ¥è¯†è’¸é¦çš„è®­ç»ƒæ–¹æ³•</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E7%9A%84%E5%8F%98%E7%A7%8D"><span class="nav-text">çŸ¥è¯†è’¸é¦çš„å˜ç§</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F%E7%9A%84-q-a"><span class="nav-text">çŸ¥è¯†è’¸é¦çš„ Q &amp; A</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8-llm-%E4%B8%AD%E7%9A%84%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F"><span class="nav-text">åœ¨ LLM ä¸­çš„çŸ¥è¯†è’¸é¦</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E7%A7%8D%E6%96%B9%E6%B3%95"><span class="nav-text">ä¸‰ç§æ–¹æ³•</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#llm-sft-%E4%B8%AD%E8%92%B8%E9%A6%8F%E7%9A%84%E7%B1%BB%E5%88%AB"><span class="nav-text">LLM SFT ä¸­è’¸é¦çš„ç±»åˆ«</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reverse-kd"><span class="nav-text">Reverse KD</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9E%E9%A1%BE-kl-%E6%8D%9F%E5%A4%B1"><span class="nav-text">å›é¡¾ KL æŸå¤±</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95"><span class="nav-text">æ–¹æ³•</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-text">å°ç»“</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#forward-kd%E7%BB%8F%E5%85%B8%E8%92%B8%E9%A6%8F"><span class="nav-text">Forward KDï¼ˆç»å…¸è’¸é¦ï¼‰</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reverse-kd-1"><span class="nav-text">Reverse KD</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8A%A8%E6%9C%BA"><span class="nav-text">åŠ¨æœº</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95-1"><span class="nav-text">æ–¹æ³•</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#approximating-kl-divergence"><span class="nav-text">Approximating KL
Divergence</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#optimization-with-policy-gradient"><span class="nav-text">Optimization with Policy
Gradient</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C"><span class="nav-text">æ¶ˆèå®éªŒ</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A7%A3%E8%80%A6%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F"><span class="nav-text">è§£è€¦çŸ¥è¯†è’¸é¦</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86"><span class="nav-text">èƒŒæ™¯çŸ¥è¯†</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%91%E7%8E%B0"><span class="nav-text">å‘ç°</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E6%B3%95-2"><span class="nav-text">æ–¹æ³•</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%93%E6%9E%9C"><span class="nav-text">ç»“æœ</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%86%99%E5%9C%A8%E6%9C%80%E5%90%8E"><span class="nav-text">å†™åœ¨æœ€å</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="wnma3mz"
      src="https://avatars.githubusercontent.com/u/23001152?s=460&u=dacc012cd237ac86458d888b3723d1d495cb1aa4&v=4">
  <p class="site-author-name" itemprop="name">wnma3mz</p>
  <div class="site-description" itemprop="description">Day Day Up</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/hexo_blog/archives/">
        
          <span class="site-state-item-count">68</span>
          <span class="site-state-item-name">æ—¥å¿—</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/hexo_blog/categories/">
          
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">åˆ†ç±»</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/hexo_blog/tags/">
          
        <span class="site-state-item-count">89</span>
        <span class="site-state-item-name">æ ‡ç­¾</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/wnma3mz" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;wnma3mz" rel="noopener" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wnma3mz@gmail.com" title="E-Mail â†’ mailto:wnma3mz@gmail.com" rel="noopener" target="_blank"><i class="envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wnma3mz</span>
</div>
  <div class="powered-by">ç”± <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> å¼ºåŠ›é©±åŠ¨
  </div>

        








      </div>
    </footer>
  </div>

  
  <script color='0,0,0' opacity='0.5' zIndex='-1' count='99' src="/hexo_blog/lib/canvas-nest/canvas-nest-nomobile.min.js"></script>
  <script src="/hexo_blog/lib/anime.min.js"></script>
  <script src="/hexo_blog/lib/velocity/velocity.min.js"></script>
  <script src="/hexo_blog/lib/velocity/velocity.ui.min.js"></script>

<script src="/hexo_blog/js/utils.js"></script>

<script src="/hexo_blog/js/motion.js"></script>


<script src="/hexo_blog/js/schemes/muse.js"></script>


<script src="/hexo_blog/js/next-boot.js"></script>




  




  
<script src="/hexo_blog/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
